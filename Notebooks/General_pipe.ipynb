{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from itertools import cycle\n",
    "from scipy import stats\n",
    "from scipy.stats import mstats\n",
    "from scipy.stats.mstats import winsorize\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "import phenograph\n",
    "import seaborn as sns\n",
    "from BorutaShap import BorutaShap, load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Libs.Dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_series(image_path):\n",
    "    \"\"\"Read all images from path and save it as array\n",
    "    param path: directory with files, str\n",
    "    return img_series: array with images, array\n",
    "    return img_names: list of file names, list\n",
    "    \"\"\"\n",
    "    all_img = []\n",
    "    img_names = []\n",
    "    for img_name in sorted(os.listdir(image_path), key=lambda x: int(x.split('.')[0])):\n",
    "        img = cv2.imread(os.path.join(image_path, img_name), cv2.IMREAD_UNCHANGED)\n",
    "        all_img.append(img)\n",
    "        img_names.append(img_name)\n",
    "    img_series = np.array(all_img)\n",
    "    return img_names, img_series\n",
    "\n",
    " def calculate_properties(contour):\n",
    "        \"\"\"\n",
    "        Calculate properties of contour\n",
    "        param contour: array with contour coordinates, np.array\n",
    "        return perimeter: len of the contour, float\n",
    "        return radius_nuclei: radius of the contour, float\n",
    "        return size: square of contour, float\n",
    "        return equi_radius: radius based on square, float\n",
    "        \"\"\"\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        radius_nuclei = perimeter / (2 * math.pi)\n",
    "        size = math.fabs(cv2.contourArea(contour))\n",
    "        equi_radius = np.sqrt(size / math.pi)\n",
    "\n",
    "        return perimeter, radius_nuclei, size, equi_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'Fucci'\n",
    "image_path = 'Dataset/'\n",
    "channels = ['0', '1', '2']\n",
    "mask_channel = '2'\n",
    "result_path = 'Datasets/'\n",
    "split_file = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(file_name=file_name, image_path=image_path, channels=channels, \n",
    "                  mask_channel=mask_channel, result_path=result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for file in os.listdir(image_path):\n",
    "    img_series = cv2.imreadmulti(os.path.join(image_path, file), flags=cv2.IMREAD_UNCHANGED)\n",
    "    img_series = np.array(img_series[1])\n",
    "    channels = cycle(channels)\n",
    "    for ind, img in enumerate(img_series):\n",
    "        if not cv2.imwrite(f'{os.path.join(result_path, next(channels))}/{str(counter)}.tif', img):\n",
    "            raise Exception('Cannot save image')\n",
    "    counter += 1\n",
    "    print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if split_file:\n",
    "    dataset.split_image_series(image_path, file_name, result_path, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#channels_renaming\n",
    "renamed_result_path = 'Datasets/renamed/'\n",
    "for c in channels:\n",
    "    path = os.path.join(result_path, c)\n",
    "    print(path)\n",
    "    os.makedirs(f'{renamed_result_path}{c}', exist_ok=True)\n",
    "    counter = 0\n",
    "    for ind in sorted(os.listdir(path), key=lambda x: int(x.split('.')[0])):\n",
    "        img = cv2.imread(os.path.join(path, ind), cv2.IMREAD_UNCHANGED)\n",
    "        img = cv2.convertScaleAbs(img)\n",
    "        norm_img = np.zeros(img.shape)\n",
    "        img = cv2.normalize(img, norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "        cv2.imwrite(f'{renamed_result_path}{c}/{counter}.tif', img)\n",
    "        counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_dir = 'Masks/Masks/2'\n",
    "contours_dir = 'Masks/Contours/2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "conturs_path = 'Masks/Contours/2'\n",
    "counter = 0\n",
    "for ind in sorted(os.listdir(conturs_path), key=lambda x: int(x.split('.')[0])):\n",
    "    os.rename(f'{conturs_path}/{ind}', f'{conturs_path}/{counter}.json')\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate base metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclei_dir = 'Nuclei/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_path = 'Masks/Masks/2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclei_summary = []\n",
    "row = []\n",
    "for c in channels:\n",
    "    save_nuclei_path = os.path.join(nuclei_dir, c)\n",
    "    os.makedirs(save_nuclei_path, exist_ok=True)\n",
    "    names, img_series = read_series(image_path=os.path.join(result_path, c))\n",
    "    for ind, img in zip(names, img_series):\n",
    "        ind = ind.split('.')[0]\n",
    "        save_nuclei_path = os.path.join(nuclei_dir, c, str(ind))\n",
    "        os.makedirs(save_nuclei_path, exist_ok=True)\n",
    "#         mask = cv2.imread(f'{mask_path}{ind}.tif', cv2.IMREAD_UNCHANGED)[:,:,0]\n",
    "#         new_mask = mask.copy()\n",
    "#         new_mask[new_mask == 0] = 0\n",
    "#         new_mask[new_mask > 1] = 255\n",
    "#         contours, hierarchy = cv2.findContours(new_mask.astype('uint8'), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "        contour_dir = f'{contours_dir}/{ind}.json'\n",
    "        with open(contour_dir) as file:\n",
    "            contours = json.load(file)\n",
    "            contours = np.array(contours['contours'])\n",
    "        contours = [np.array(x) for x in contours]\n",
    "        for z in range(0,len(contours)):\n",
    "            perimeter, radius_nucl, size, equi_radius = calculate_properties(contours[z])\n",
    "            nucl_ind = str(ind)+'_'+str(z)\n",
    "            x, y, w, h = cv2.boundingRect(contours[z])\n",
    "            if ((h/w)>2) or ((w/h)>2):\n",
    "                continue\n",
    "            mask2 = np.zeros(img.shape, np.uint8)\n",
    "            cv2.fillPoly(mask2, pts =[contours[z]], color=(255))\n",
    "            temp2 = cv2.bitwise_and(img, img, mask=mask2)\n",
    "            roi = temp2[y:y + h, x:x + w]\n",
    "            mean_pixel = roi.sum()/len(np.where(roi > 0)[1])\n",
    "            max_pixel = roi.max()\n",
    "            row = [file_name, ind, z, nucl_ind,\n",
    "            perimeter, size, equi_radius, radius_nucl, mean_pixel, max_pixel, c]\n",
    "            nuclei_summary.append(row)\n",
    "            cv2.imwrite(f'{save_nuclei_path}/{nucl_ind}.tif', roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = 'Dataframes/'\n",
    "nuclei_df = pd.DataFrame(nuclei_summary, columns = ['series', 'image_id', 'index', 'nucl_ind',\n",
    "                                         'perimeter', 'size', 'equi_radius', 'radius', 'mean_pixel',\n",
    "                                         'max_pixel', 'channel'])\n",
    "\n",
    "nuclei_metric = nuclei_df.drop(columns=['mean_pixel', 'max_pixel', 'channel'])\n",
    "nuclei_metric = nuclei_metric.drop_duplicates().set_index('nucl_ind').sort_index()\n",
    "shorted = nuclei_df[['nucl_ind','max_pixel','channel']].fillna(0).drop_duplicates()\n",
    "shorted2 = shorted.pivot(index='nucl_ind', columns='channel',values='max_pixel')\n",
    "shorted2 = shorted2.sort_index()\n",
    "nuclei_metric[['channel_0', 'channel_1', 'channel_2']] = shorted2[['0', '1', '2']]\n",
    "nuclei_metric = nuclei_metric.fillna(0)\n",
    "nuclei_metric.to_csv(f'{df_path}/max_metrics.csv')\n",
    "\n",
    "nuclei_metric = nuclei_df.drop(columns=['mean_pixel', 'max_pixel', 'channel'])\n",
    "nuclei_metric = nuclei_metric.drop_duplicates().set_index('nucl_ind').sort_index()\n",
    "shorted = nuclei_df[['nucl_ind','mean_pixel','channel']].fillna(0).drop_duplicates()\n",
    "shorted2 = shorted.pivot(index='nucl_ind', columns='channel',values='mean_pixel')\n",
    "shorted2 = shorted2.sort_index()\n",
    "nuclei_metric[['channel_0', 'channel_1', 'channel_2']] = shorted2[['0', '1', '2']]\n",
    "nuclei_metric = nuclei_metric.fillna(0)\n",
    "nuclei_metric.to_csv(f'{df_path}/mean_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_name in os.listdir('Nuclei/2'):\n",
    "    for nucl_name in os.listdir(f'Nuclei/2/{img_name}'):\n",
    "        img = cv2.imread(f'Nuclei/2/{img_name}/{nucl_name}', cv2.IMREAD_UNCHANGED)\n",
    "        cv2.imwrite(f'Nuclei/2_all/{nucl_name}', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Texture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Libs.classification as classification\n",
    "from Libs.features_extraction import HaralickFeatures, TAS, \\\n",
    "ZernikeMoments, extract, Preprocess, CenterMass, ChromatinFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {'features': [HaralickFeatures(), TAS(), ZernikeMoments(None), CenterMass(), ChromatinFeatures()],\n",
    "            'feat_num' : [13, 54, 25, 2, 4],\n",
    "            'objects_1' : 2230,\n",
    "            'object_1_class': 'Fucci'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = classification.dataCollection('Nuclei/2_all', features, preproc_commands = [], normalize=True, enhance=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Dataframes/textures.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skshape.image.segmentation import segment_phase_field\n",
    "from skshape.geometry import triangulation_from_labels\n",
    "from skshape.image.enhancement import weighted_smoothing\n",
    "\n",
    "from karateclub import GeoScattering\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_triangulation(img, mask):\n",
    "    \"\"\"\n",
    "    Calculate triangulation in the mask and filter it to keep triangles only in the cell:\n",
    "    param mask: grayscale mask, numpy array\n",
    "    return curves: array with curves, numpy array\n",
    "    return vertices: array with all coordinates, numpy array\n",
    "    return new_triangles: array with filtered triangles, numpy array\n",
    "    \"\"\"\n",
    "    curves, vertices, triangles = triangulation_from_labels(mask, smooth_boundaries=False, coarsen_boundaries=False)\n",
    "    filter_list = np.empty(vertices.shape[0], dtype=np.float32)\n",
    "    scale_x = img.shape[:2][0]\n",
    "    scale_y = img.shape[:2][1]\n",
    "    init_mask = (img > 0.2)\n",
    "    contours_cell, hierarchy = cv2.findContours(init_mask.astype('uint8'),\n",
    "                                                cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    for i in range(vertices.shape[0]):\n",
    "        x = scale_x * vertices[i][1]\n",
    "        y = scale_y * vertices[i][0]\n",
    "        coordinates = (x, y)\n",
    "        filter_list[i] = cv2.pointPolygonTest(contours_cell[0], coordinates, False)\n",
    "    new_triangles = []\n",
    "    for i in triangles:\n",
    "        counter = 0\n",
    "        for x in i:\n",
    "            if filter_list[x] > 0:\n",
    "                continue\n",
    "            else:\n",
    "                counter += 1\n",
    "        if counter == 0:\n",
    "            new_triangles.append(i)\n",
    "    new_triangles = np.array(new_triangles)\n",
    "\n",
    "    return new_triangles\n",
    "\n",
    "def generate_triangle_df(img_path, mask_path):\n",
    "\n",
    "    nuclei_df2 = {}\n",
    "    for img_name in os.listdir(mask_path):\n",
    "        print(os.path.join(mask_path, img_name))\n",
    "        mask = cv2.imread(os.path.join(mask_path, img_name), cv2.IMREAD_UNCHANGED)[:, :, 0]\n",
    "        img = cv2.imread(os.path.join(img_path, img_name), cv2.IMREAD_UNCHANGED)\n",
    "        new_triangles = calculate_triangulation(img, mask)\n",
    "        nuclei_df2[img_name.split('.')[0]] = new_triangles\n",
    "\n",
    "    reindexed_df2 = {}\n",
    "    for key in nuclei_df2:\n",
    "        G = nx.Graph()\n",
    "        for path in nuclei_df2[key]:\n",
    "            nx.add_path(G, path)\n",
    "        mapping = {}\n",
    "        counter = 0\n",
    "        for n in np.unique(nuclei_df2[key]):\n",
    "            mapping[n] = counter\n",
    "            counter += 1\n",
    "        H = nx.relabel_nodes(G, mapping, copy=True)\n",
    "        if len(H) < 2:\n",
    "            continue\n",
    "        if not nx.is_connected(H):\n",
    "            continue\n",
    "        model = GeoScattering(3)\n",
    "        model.fit([H])\n",
    "        X = model.get_embedding()\n",
    "        reindexed_df2[key] = X\n",
    "\n",
    "    new_df2 = pd.DataFrame()\n",
    "    for x in reindexed_df2:\n",
    "        series = reindexed_df2[x]\n",
    "        seq = pd.Series(series[0], name=x)\n",
    "        new_df2 = new_df2.append(seq)\n",
    "\n",
    "    return new_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangulation_df = generate_triangle_df('Nuclei/2_all', 'Masks/Nuclei_chromo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangulation_df.to_csv('Dataframes/triangulations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = { \n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(size=224),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomResnet(nn.Module):\n",
    "        def __init__(self, resnet50):\n",
    "            super(CustomResnet, self).__init__()\n",
    "            self.resnet50 = resnet50\n",
    "            self.resnet50.fc = nn.Linear(2048, 256)\n",
    "            self.internalfeature = nn.Sequential(nn.Linear(256, 32))\n",
    "            self.finalfeature = nn.Sequential(nn.Linear(32, 4))\n",
    "            \n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.resnet50(x))\n",
    "            x = F.relu(self.internalfeature(x))\n",
    "            x = self.finalfeature(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_image_name):\n",
    "    transform = image_transforms['test']\n",
    "    test_image = Image.open(test_image_name)\n",
    "    test_image = test_image.resize((224, 224), Image.ANTIALIAS)\n",
    "    test_image = test_image.convert('RGB')\n",
    "    test_image_tensor = transform(test_image)\n",
    "    if torch.cuda.is_available():\n",
    "        test_image_tensor = test_image_tensor.view(1, 3, 224, 224).to(device)\n",
    "    else:\n",
    "        test_image_tensor = test_image_tensor.view(1, 3, 224, 224)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        out = model(test_image_tensor)\n",
    "        ps = torch.exp(out)\n",
    "        topk, topclass = ps.topk(1, dim=1)\n",
    "        return topclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomResnet(models.resnet50(pretrained=False))\n",
    "# model = models.resnet50(pretrained=True)\n",
    "model.load_state_dict(torch.load('Models/classifier_custom_resnet50_4_classes.pth'))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = 'Nuclei/2_all/'\n",
    "summary_dr = []\n",
    "for i in os.listdir(img_dir):\n",
    "    print(i)\n",
    "    image_name = f'{img_dir}/{i}'\n",
    "    image = Image.open(image_name)\n",
    "    transform = image_transforms['test']\n",
    "    feature_extractor = torch.nn.Sequential(*list(model.children())[:-1])\n",
    "    test_image = image.convert('RGB')\n",
    "    test_image_tensor = transform(test_image)\n",
    "    test_image_tensor = test_image_tensor.view(1, 3, 224, 224)\n",
    "    output = feature_extractor(test_image_tensor)\n",
    "    output = output.detach().cpu().numpy()\n",
    "    clas = predict(model, image_name)\n",
    "    clas = clas.detach().cpu().numpy()[0][0]\n",
    "    cell_name = i.split('.')[0]\n",
    "    output = np.append(output, clas)\n",
    "    output = np.append(output, cell_name)\n",
    "    summary_dr.append(output)\n",
    "summary_dr = pd.DataFrame(summary_dr)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dr.to_csv('Dataframes/classifier_custom_32f.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuclei filtration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_metrics = pd.read_csv('Dataframes/max_metrics.csv').set_index('nucl_ind')\n",
    "mean_metrics = pd.read_csv('Dataframes/mean_metrics.csv').set_index('nucl_ind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df = pd.read_csv('Dataframes/qc_brightness.csv').set_index('cell_name')\n",
    "filter_df = filter_df.loc[filter_df['type'] == 'normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "textures = pd.read_csv('Dataframes/textures.csv').set_index('cell_name')\n",
    "textures = textures.loc[filter_df.index]\n",
    "textures = textures.dropna()\n",
    "standard_scaler = preprocessing.StandardScaler()\n",
    "textures_norm = textures.copy(deep=True)\n",
    "for c in textures.columns:\n",
    "    x = textures[c].values.reshape(-1, 1)\n",
    "    x_scaled = standard_scaler.fit_transform(x)\n",
    "    textures_norm[c] = x_scaled\n",
    "actual_metrics = mean_metrics.loc[textures_norm.index]\n",
    "z_scores = stats.zscore(actual_metrics[['channel_0', 'channel_1']])\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "textures_norm_filt = textures_norm[filtered_entries]\n",
    "print(textures.shape)\n",
    "textures.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mesh_embedding_df = pd.read_csv('Dataframes/triangulations.csv').set_index('Unnamed: 0')\n",
    "mesh_embedding_df = mesh_embedding_df.loc[filter_df.index]\n",
    "mesh_embedding_df = mesh_embedding_df.dropna()\n",
    "standard_scaler = preprocessing.StandardScaler()\n",
    "mesh_norm = mesh_embedding_df.copy(deep=True)\n",
    "for c in mesh_norm.columns:\n",
    "    x = mesh_norm[c].values.reshape(-1, 1)\n",
    "    x_scaled = standard_scaler.fit_transform(x)\n",
    "    mesh_norm[c] = x_scaled\n",
    "actual_metrics = mean_metrics.loc[mesh_norm.index]\n",
    "z_scores = stats.zscore(actual_metrics[['channel_0', 'channel_1']])\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "mesh_norm_filt = mesh_norm[filtered_entries]\n",
    "print(mesh_norm_filt.shape)\n",
    "mesh_norm_filt.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_df = pd.read_csv('Dataframes/classifier_custom_32f.csv').set_index('33', drop=True).drop(['32'], axis=1)\n",
    "classifier_df = classifier_df.loc[filter_df.index]\n",
    "standard_scaler = preprocessing.StandardScaler()\n",
    "classifier_norm = classifier_df.copy(deep=True)\n",
    "for c in classifier_df.columns:\n",
    "    x = classifier_df[c].values.reshape(-1, 1)\n",
    "    x_scaled = standard_scaler.fit_transform(x)\n",
    "    classifier_norm[c] = x_scaled\n",
    "actual_metrics = mean_metrics.loc[classifier_norm.index]\n",
    "z_scores = stats.zscore(actual_metrics[['channel_0', 'channel_1']])\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "classifier_norm_filt = classifier_norm[filtered_entries]\n",
    "classifier_norm_filt.shape\n",
    "classifier_norm_filt.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Textures clusterization\n",
    "textures_clust = textures_norm_filt.copy(deep=True)\n",
    "communities, graph, Q = phenograph.cluster(textures_clust, primary_metric='cosine', n_jobs=10, k=350, min_cluster_size=5, clustering_algo='leiden')\n",
    "communities = pd.Series(communities, name='phenograph_cluster', index=textures_clust.index)\n",
    "textures_clustered = pd.concat([textures_clust, communities], axis=1)\n",
    "print(communities.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Textures_clusters\n",
    "actual_metrics = mean_metrics.loc[textures_clustered.index]\n",
    "textures_clustered_vis = textures_clustered.copy(deep=True)\n",
    "textures_clustered_vis[['channel_0', 'channel_1']] = actual_metrics[['channel_0', 'channel_1']]\n",
    "actual_metrics = mean_metrics.loc[textures_clustered_vis.index]\n",
    "z_scores = stats.zscore(actual_metrics[['channel_0', 'channel_1']])\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "textures_clustered_vis = textures_clustered_vis[filtered_entries]\n",
    "stand_scaler = preprocessing.MinMaxScaler()\n",
    "x = textures_clustered_vis['channel_0'].values.reshape(-1, 1)\n",
    "x_scaled = stand_scaler.fit_transform(x)\n",
    "textures_clustered_vis['channel_0'] = x_scaled\n",
    "x = textures_clustered_vis['channel_1'].values.reshape(-1, 1)\n",
    "x_scaled = stand_scaler.fit_transform(x)\n",
    "textures_clustered_vis['channel_1'] = x_scaled\n",
    "\n",
    "g = sns.FacetGrid(textures_clustered_vis, col=\"phenograph_cluster\", hue=\"phenograph_cluster\", col_wrap=5)\n",
    "# g = sns.FacetGrid(textures_clustered_vis, col=\"k_cluster\", hue=\"k_cluster\", col_wrap=5)\n",
    "g.map(sns.scatterplot, \"channel_0\", \"channel_1\", s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Mesh clusterization\n",
    "mesh_embedding_df_clust = mesh_norm_filt.copy(deep=True)\n",
    "communities, graph, Q = phenograph.cluster(mesh_embedding_df_clust, primary_metric='cosine', n_jobs=10, k=350, min_cluster_size=5)\n",
    "communities = pd.Series(communities, name='phenograph_cluster', index=mesh_embedding_df_clust.index)\n",
    "mesh_clustered = pd.concat([mesh_embedding_df_clust, communities], axis=1)\n",
    "print(communities.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Classifier clusterization\n",
    "classifier_df = classifier_norm_filt.copy(deep=True)\n",
    "communities, graph, Q = phenograph.cluster(classifier_df, primary_metric='cosine', n_jobs=-1, k=350, min_cluster_size=5, clustering_algo='louvain')\n",
    "communities = pd.Series(communities, name='phenograph_cluster', index=classifier_df.index)\n",
    "comb_clustered = pd.concat([classifier_df, communities], axis=1)\n",
    "print(communities.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classifier_clusters\n",
    "actual_metrics = mean_metrics.loc[classifier_clustered.index]\n",
    "classifier_clustered_vis2 = comb_clustered\n",
    "classifier_clustered_vis2[['channel_0','channel_1']] = actual_metrics[['channel_0', 'channel_1']]\n",
    "z_scores = stats.zscore(classifier_clustered_vis2[['channel_0', 'channel_1']])\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "classifier_clustered_vis2_filt = classifier_clustered_vis2[filtered_entries]\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x = classifier_clustered_vis2['channel_1'].values.reshape(-1, 1)\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "classifier_clustered_vis2['channel_1'] = x_scaled\n",
    "x = classifier_clustered_vis2['channel_0'].values.reshape(-1, 1)\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "classifier_clustered_vis2['channel_0'] = x_scaled\n",
    "\n",
    "g = sns.FacetGrid(classifier_clustered_vis2, col=\"phenograph_cluster\", hue=\"phenograph_cluster\", col_wrap=5)\n",
    "# g = sns.FacetGrid(classifier_clustered_vis2, col=\"k_cluster\", hue=\"k_cluster\", col_wrap=5)\n",
    "g.map(sns.scatterplot, \"channel_0\", \"channel_1\", size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Textures\n",
    "textures_matr = textures_clustered.drop(['phenograph_cluster'], axis=1)\n",
    "projection_model = UMAP(n_components=2, n_neighbors=350,  metric='cosine',\n",
    "                 random_state=42, transform_seed=42)\n",
    "projection = pd.DataFrame(projection_model.fit_transform(textures_matr),\n",
    "                          columns=['v0', 'v1'])\n",
    "# projection_model = MulticoreTSNE.MulticoreTSNE(n_jobs=10, perplexity=350, random_state=42,n_iter=5000)\n",
    "# projection = projection_model.fit_transform(sample_data_matr)\n",
    "cluster_centers = pd.concat([projection, textures_clustered['phenograph_cluster'].reset_index()], axis=1)\n",
    "cluster_centers = cluster_centers.groupby('phenograph_cluster').median().reset_index()\n",
    "\n",
    "cluster_pallete = {\n",
    "    i[1]: i[0]\n",
    "    for i in zip(sns.color_palette('Set2', n_colors=len(textures_clustered['phenograph_cluster'].unique())),\n",
    "                 textures_clustered['phenograph_cluster'].unique())\n",
    "}\n",
    "ax.scatter(projection['v0'],\n",
    "           projection['v1'],\n",
    "           s=60,\n",
    "           c=textures_clustered['phenograph_cluster'].map(cluster_pallete)\n",
    ")\n",
    "for _, row in cluster_centers.iterrows():\n",
    "    ax.annotate(row['phenograph_cluster'], row[['v0', 'v1']], size=5)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Mesh\n",
    "mesh_matr = mesh_clustered.drop(['phenograph_cluster'], axis=1)\n",
    "projection_model = UMAP(n_components=2, n_neighbors=50,  metric='correlation',\n",
    "                 random_state=42, transform_seed=42)\n",
    "projection = pd.DataFrame(projection_model.fit_transform(mesh_matr),\n",
    "                          columns=['v0', 'v1'])\n",
    "\n",
    "# projection_model = MulticoreTSNE.MulticoreTSNE(n_jobs=10, perplexity=350, random_state=42,n_iter=5000)\n",
    "# projection = projection_model.fit_transform(sample_data_matr)\n",
    "cluster_centers = pd.concat([projection, mesh_clustered['phenograph_cluster'].reset_index()], axis=1)\n",
    "cluster_centers = cluster_centers.groupby('phenograph_cluster').median().reset_index()\n",
    "\n",
    "cluster_pallete = {\n",
    "    i[1]: i[0]\n",
    "    for i in zip(sns.color_palette('Set2', n_colors=len(mesh_clustered['phenograph_cluster'].unique())),\n",
    "                 mesh_clustered['phenograph_cluster'].unique())\n",
    "}\n",
    "ax.scatter(projection['v0'],\n",
    "           projection['v1'],\n",
    "           s=6,\n",
    "           c=mesh_clustered['phenograph_cluster'].map(cluster_pallete)\n",
    ")\n",
    "for _, row in cluster_centers.iterrows():\n",
    "    ax.annotate(row['phenograph_cluster'], row[['v0', 'v1']], size=5)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Classifier\n",
    "classifier_matr = classifier_clustered_vis.drop(['phenograph_cluster'], axis=1)\n",
    "projection_model = UMAP(n_components=2, n_neighbors=350,  metric='correlation',\n",
    "                 random_state=42, transform_seed=42)\n",
    "projection = pd.DataFrame(projection_model.fit_transform(classifier_matr),\n",
    "                          columns=['v0', 'v1'])\n",
    "\n",
    "# projection_model = MulticoreTSNE.MulticoreTSNE(n_jobs=10, perplexity=350, random_state=42,n_iter=5000)\n",
    "# projection = projection_model.fit_transform(sample_data_matr)\n",
    "cluster_centers = pd.concat([projection, classifier_clustered_vis['phenograph_cluster'].reset_index()], axis=1)\n",
    "cluster_centers = cluster_centers.groupby('phenograph_cluster').median().reset_index()\n",
    "\n",
    "cluster_pallete = {\n",
    "    i[1]: i[0]\n",
    "    for i in zip(sns.color_palette('Set2', n_colors=len(classifier_clustered_vis['phenograph_cluster'].unique())),\n",
    "                 classifier_clustered_vis['phenograph_cluster'].unique())\n",
    "}\n",
    "ax.scatter(projection['v0'],\n",
    "           projection['v1'],\n",
    "           s=2,\n",
    "           c=classifier_clustered_vis['phenograph_cluster'].map(cluster_pallete)\n",
    ")\n",
    "for _, row in cluster_centers.iterrows():\n",
    "    ax.annotate(row['phenograph_cluster'], row[['v0', 'v1']], size=5)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample = textures_clustered_vis.groupby('phenograph_cluster', group_keys=False).apply(lambda x: x.sample(80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_select = subsample\n",
    "X, y = df_for_select.drop(['phenograph_cluster'], axis=1), df_for_select['phenograph_cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier,XGBRegressor\n",
    "model = XGBClassifier()\n",
    "Feature_Selector = BorutaShap(model=model, importance_measure='shap',\n",
    "                              classification=True)\n",
    "\n",
    "Feature_Selector.fit(X=X, y=y, n_trials=30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature_Selector.TentativeRoughFix()\n",
    "Feature_Selector.plot(which_features='all', \n",
    "                      X_size=8, figsize=(12,8),\n",
    "                      y_scale='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = ['11', '0', '4', '22', '13', '14', '2', '18', '19', '9', '3', '8', '26', '6', '5', '23', '29']\n",
    "metric2 = ['ZernikeMoments_#24', 'HaralickFeatures_#12', 'ZernikeMoments_#17', 'TAS_#02', 'ZernikeMoments_#23', 'TAS_#10', 'ZernikeMoments_#06', 'TAS_#01', 'HaralickFeatures_#05', 'channel_1', 'TAS_#19', 'ZernikeMoments_#22', 'HaralickFeatures_#08', 'ZernikeMoments_#13', 'TAS_#26', 'TAS_#46', 'TAS_#39', 'HaralickFeatures_#11', 'TAS_#37', 'ZernikeMoments_#04', 'TAS_#29', 'TAS_#11', 'HaralickFeatures_#13', 'ZernikeMoments_#15', 'ZernikeMoments_#14', 'ZernikeMoments_#03', 'TAS_#08', 'HaralickFeatures_#06', 'TAS_#18', 'TAS_#28', 'TAS_#30', 'HaralickFeatures_#09', 'ZernikeMoments_#12', 'ZernikeMoments_#07', 'TAS_#43', 'TAS_#20', 'ZernikeMoments_#05', 'TAS_#09']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
